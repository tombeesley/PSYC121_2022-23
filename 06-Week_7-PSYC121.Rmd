---
output:
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---


```{r eval=FALSE, include=FALSE}
library(tidyverse)
options(scipen = 999) # this stops numbers appearing as scientific notation

load("survey_raw.RData")

# set up the data for Task 3
d <- 
  data %>% 
  select(uk_salary, sibling_order, home_location, home_location_in_UK, attention_check = attention_check_2) %>%
  mutate(sibling_order = case_when(str_detect(sibling_order, "oldest") ~ "oldest",
                                   str_detect(sibling_order, "middle") ~ "middle",
                                   str_detect(sibling_order, "youngest") ~ "youngest",
                                   str_detect(sibling_order, "only") ~ "only"),
         home_location_in_UK = case_when(str_detect(home_location_in_UK, "North West") ~ "NW",
                                         str_detect(home_location_in_UK, "North East") ~ "NE",
                                         str_detect(home_location_in_UK, "South West") ~ "SW",
                                         str_detect(home_location_in_UK, "South East") ~ "SE",
                                         str_detect(home_location_in_UK, "Midlands") ~ "Midlands",
                                         str_detect(home_location_in_UK, "Wales") ~ "Wales"),
         attention_check = case_when(str_detect(attention_check, "strongly dis") ~ "strongly disagree",
                                     TRUE ~ attention_check)) %>% 
  write_csv("files/Week_7/salary_data_wk7.csv")

```

# Week 7: Filtering data and testing means (one-sample t-test)

> Written by Tom Beesley & John Towse

Today we will look in a bit more detail at people's estimates of the average UK salary. We will first plot this data using `geom_histogram()` and also `geom_boxplot()`. When we do this, we'll see that there are some unusual values, and we'll need to do a bit of **data wrangling** to remove them, using the `filter()` command. We'll then turn to the conceptual ideas of the lecture - how can we tell if the mean of our sample is unusual, or whether we would actually expect this mean value under the null hypothesis? Finally, we'll continue to develop our skills in **data visualisation** by exploring `geom_density()` plots.

## Pre-lab work

- There is an [online tutorial](https://ma-rconnect.lancs.ac.uk/PSYC121_Week_7_labprep/){target="_blank"}. Please make every attempt to complete this before the lab! 


- Create a folder for Week 7

- Download the [Week_7.zip](files/Week_7/Week_7.zip) and upload it into this new folder in RStudio Server. 

## RStudio tasks

### Plotting and filtering

1. Open the Week_7_script and run the `library`, `options` commands. The `options` command is new. It is very cryptic and you don't need to worry too much about this - it is making sure that the values in the graphs are displayed as regular numbers and not as scientific notation. Add a `read_csv()` command to get the data - you've done this every week, so this should be familiar. 

2. Complete the `geom_histogram()` code to plot the distribution of salary data. Try setting `bins=20` within your `geom_histogram()` code. Play around with the number of bins for the histogram.

3. OK - we've got some pretty funky values here! Some people think the average salary is over £400,000!!! Well, maybe they just added too many zeros (let's give them the benefit of the doubt). Quite often when we get our "raw" data, it contains weird values like this that we need to consider removing. Let's run the `arrange()` code now to see what exactly those high values are.

4. We'll need to remove these high values to get a better sense of the distribution. Let's use a `filter()` command to do this. We need to make a decision about what values to exclude. In later labs we'll look at a more systematic process of removing *outliers*, but for now, let's just remove any that are over £200,000. Edit the `filter()` command to keep only those estimates that are *below* £200,000 (<). Remember that the filter command *keeps* the data that is *TRUE* according to the expression. 

5. STOP! OK, **this next bit is very important**. If you completed that last step correctly you'll see an output in the console showing a "tibble" (a data frame) which has 194 rows and 5 columns. However, your object has not actually changed in the environment. This will still be showing as 197 observations (row). So the filter command will take out those large estimations, but we haven't actually changed the data object. To do this we need to assign (`<-`)the result of our filter command to the object. To do this, you need to put in some code at the start of this small chunk of code you've just run, so that the result of your commands will be assigned to the object (you can make this the same object name you've been using -overwrite it-, or call it a new name).

6. When you run this command again you should see the (new) object has changed to 194 rows. We can now plot the data again as a histogram. To do this, copy the earlier code for the histogram and edit it as necessary (if you're using a new object for the filtered data, you'll need to edit the code to reflect that). .

7. And as you know, we can also look at the distribution as a boxplot, a violin, or a density plot. Feel free to add in your own code for other visualisations you might like to try. 

### One-sample t-test

We now want to know if the salary estimates are different to the actual average salary in the UK (which is approx. £30,000). Our hypothesis might be that people are inaccurate - they overestimate or underestimate the average UK salary. Let's test that.

8. First, let's calculate the mean and sd of the column.

9. Now we can compute a t-statistic and check whether this mean is significantly different from the expected mean. We do this with `t.test()`. Edit the code on this line to conduct a one-sample t-test. You need to provide **the sample of data on which you want to conduct the test**, and the **expected mean under the null hypothesis**. Remember our hypothesis is that people are not accurate. Your calculation of the mean should tell you whether they numerically overestimated or underestimated. But would we expect such a result under the null hypothesis? Run the t-test and **note the p value**. How likely is it that we would see this sample of data (this mean value and the distribution of data - the SD) under the null hypothesis? The p value ranges from 0 to 1. If it is very low - typically we say p < .05 - then we conclude our result is unlikely under the null hypothesis and it is therefore a *significant result*.

10. What is the critical value of t in the t-distribution table, for this sample size? Degrees of freedom is N - 1.


![](files/Week_7/ttable.png) 

### Practising filtering

11. Filtering can also be useful for selecting certain sub-sets of our data. In the script we have given you an example of how we select a sub-set of data based on two conditions from two different columns:

`data_set_name %>% filter(home_location_in_UK == "NW" & sibling_order == "oldest")`
  
We have given you a few different columns to look at and to use in practicing your filter commands:

`sibling_order`: what position in age was the respondent within their siblings
`home_location`: UK / Asia / Europe, etc
`home_location_in_UK`: NW, NE, etc (NA is non-UK residents)
`attention_check`: respondents were asked "click strongly agree to show you are paying attention" - some people failed this!!!

Complete the following filters. We've put in **()** the number of rows you should see in the resulting object

12. Just those people who come from the North East (16 rows)

13. Those people who come from Wales and are the middle child within their siblings (2 rows)

14. Those people passed the attention check, are from the UK, and are an only child (21 rows)

15. Those people who are NOT from the North West; you'll need to use `!=` (84 rows)

16. Those people who failed the attention check (that is, did not say strongly agree) (14 rows)

17. Those people who are from the South East or (`|`) the South West (38 rows)

## Sample size, size of effect, and the one sample t-test

In the lecture this week, Tom used an application to show the process of sampling data. You can access this application at the link below. There are three "parameters" you can change in this:

- **The true mean of the effect:** Think of this like the bias that was set up in your deck of cards last week. There is some true state out there in the world, and we are going to draw samples from a distribution of data that has a mean that equals this value. If you make this 100, then the true mean is equal to that under the null hypothesis (there is no effect).

- **The standard deviation of the data:** This sets how variable the data are in this population. If the data are more variable, then our samples will produce estimations that are less accurate of the true mean value.

- **The sample size:** How many observations are drawn in the sample. These are represented by the yellow circles in the plot.

Each time you draw a sample the data points are plotted in yellow and the mean of the sample is marked with the red line. The application also runs a one-sample t-test against the expected mean under the null hypothesis, of 100. The null hypothesis is also represented by the static distribution presented in grey, centred on 100.

Things to try:

1. Start with a sample size of 10, and a mean of the effect of 110 (SD = 15). How often do you get a significant result (p < .05) when you draw a new sample?

2. Now try changing the mean of the effect to 120. Does this increase or decrease the likelihood of getting significant results? What about changing to 130?

3. Now keep the mean effect constant (say 110), but increase the sample size. Try 5, then 10, 15, and so on. Does this increase or decrease the likelihood of getting significant results?

4. Set the mean of the effect to 100 and the sample size to 10. Keep drawing new samples, noting each time the p value. You will evenutally get a p value of < .05. What type of error is this?


[**Click here for the one-sample t-test application**](https://ma-rconnect.lancs.ac.uk/one_sample_t){target="_blank"}

## Week 6 Quiz

You can access a set of quiz questions related to this week [here.](https://ma-rconnect.lancs.ac.uk/PSYC121_2022_Week_7_Quiz/){target="_blank"}