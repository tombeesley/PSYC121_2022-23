---
output:
  html_document: default
  pdf_document: default
---


```{r eval=FALSE, include=FALSE}
library(tidyverse)
load("survey_raw.RData")

colnames(data)

data_wk9 <- 
  data %>% 
  mutate(home_location_in_UK = case_when(str_detect(home_location_in_UK, "North") ~ "North",
                                         str_detect(home_location_in_UK, "South") ~ "South")) %>% 
    select(contains("pop"), home_location_in_UK) %>% 
  drop_na()

write_csv(data_wk9, file = "files/Week_9/data_wk9.csv")

```

# Week 9: Unrelated-samples t-test and Power 

> Written by Tom Beesley & John Towse

## Pre-lab work: online tutorial

**Online tutorial**: You must make every attempt to complete this before the lab! To access the [**pre-lab tutorial click here**](https://ma-rconnect.lancs.ac.uk/Week_9_LabPrep){target="_blank"} (on campus, or VPN required)

**Getting ready for the lab class** 

Create a folder for Week 9. and download the [week_9.zip](files/Week_9/week_9.zip) file and upload it into this new folder in RStudio Server. 

## RStudio tasks

### Exploring the data 

In this class we will be exploring some data on people's estimations on aspects of the UK population. We asked people 4 different questions:

>Out of every 100 people, about how many do you think are:

>1. Christian?
>2. Muslim?
>3. Over the age of 65?

We also asked a related question about immigration:

>What percentage of the UK population do you think are immigrants to this country? (i.e. not born in UK)

1. Read in the data "data_wk9.csv" using `read_csv()`.

2. Take a look at the summary statistics for all of the columns in our data using `summary()`

3. At this stage you could try using `ggplot()` with `geom_histogram()` (hint: not sure? look at last week) or `geom_density()` to explore the different columns.

4. You may be tempted at this stage to apply the `filter()` commands to remove any outliers. If so, yes, that's entirely sensible. But note that we are going to remove outliers a little further into our tasks after we've first done some visualisation.


### Visualising relationships in the data 

To what extent are people's estimations of these population parameters related? Let's look at this by plotting these data as `geom_point()`: 

1. Complete the code to add one numeric column in the data to x and another numeric column to y. You can pick any of the columns you like, but it's important that you understand what research question you are asking with your choice. For example, you might be asking "Do people who estimate there are more Christians in the population also think there are more people over the age of 65?"

2. Note the general pattern in the data. Is there a *postive relationship*: do people who give high estimations for one variable tend to give high estimations for the other variable? Or is there a *negative relationship*: do people who give high estimations for one variable tend to give lower estimations for the other variable? Or is there no discernable relationship at all?

3. Copy the code and edit it to explore relationships between the other numeric variables, each time noting the research question you are asking, and discussing on your table what kind of relationship you can see in the data.  

### Using z-scores to remove outliers

1. You may have noticed that there are some fairly extreme values in some of these numeric estimations of the population. As we've discussed in previous weeks, these outlier values can be problematic when we run our statistical tests, so (like last week) we probably want to control their influence by removing them. As you saw in your online tutorial, we can convert the data to z scores, and then remove z values above and below certain values.

2. Let's create a "z-transform column" called *z_imm* for the estimates of the percentage of immigrants. Complete the code you have been given by adding the relevant variable (column) name to the code. You may want to create a new data object at this point. 

3. View the new data object to check this column has been created correctly. Like in the online tutorial, it would be a good idea to calculate some descriptive statistics for these new columns to check it conforms to what we know about z-scores (e.g., `mean()` should be very close to 0, `sd()` = 1). Note, if you want to change the output in r from scientific notation to non-scientific notation, you can run the command `options(scipen=999)`. 

4. We know from our lectures on the z distribution that values of greater than 2 (or less than -2) reflect around 5% of the distribution, and values greater than 3 (or less than -3) represent less than 1% of the distribution:

![](files/Week_9/z_score_figure.png)

5. Let's consider an outlier any value that has a z of 2.5 (a conventional cutoff). Plot a histogram of the *z_imm* column in order to inspect whether there are data that are above 2.5 or below -2.5.

6. Add a filter command to remove the values in the *z_imm* column are greater than 2.5 or less than -2.5. 


## Unrelated samples t-test

We have also included a categorical variable in our data this week, which is one you have seen before in our analysis classes: the home location in the UK of the respondent, `home_location_in_UK`. For this data object we have included only those responses from those people from the "North" (NW and NE) and those from the "South" (SW and SE). Other respondents from elsewhere have been removed from the data. We can therefore look at whether people's home location determines their population estimations.  

1. First we will look at the mean population estimations, split by home location. To do this, complete the `group_by()` and `summarise()` commands to give the mean estimates of the proportion of muslims in the population by home location.  You don't need to edit the `N = n()` line - this provides the number of participants at each level of the *home_location_in_UK* variable. 

2. What do the means suggest? Do people in the North and South give different estimations? 

3. Let's test if these differences are real. First, it is worth noting that many more respondents originate from the North than from the South (see the *N* column in the summary). We have unequal sample sizes, and potentially unequal variances. Run the `var.test()` code to check if the variances of the two samples are similar (homogeneity of variance). If this test produces a p value less that .05, then the variances in the two samples are unequal. That will have consequences for how we run the `t-test()` in the next step. 

4. Now let's run the t-test. This week we are comparing data from different samples of participants (those who are from the North and South). We need to tell the t-test that the data are NOT paired (`paired = FALSE`). The result of the `var.test()` in the last step will tell you whether the `var.equal` value should be `TRUE` or `FALSE`.  Set `var.equal = FALSE` or `var.equal = TRUE` depending on whether the variances are equal. When you're happy with the parameters, run the t-test. What result did you get and what does this mean? Discuss this with your table, or with the staff in the lab.

5. In that t-test we looked at the *pop_est_muslim* variable, but we can do this test for all of our population estimates. Copy the code to run another `var.test()` and `t.test()`, for the *pop_est_christian* variable. Note the t and p values; What do these tell us about the relationship between music preference and social media use? You can also run two further tests on the other population estimations. 

## Power and effect size (d) calculations

1. We saw in last week's lab tasks that there was a significant effect in our Stroop task data: participants were faster to say the colour names of the compatible list compared to the incompatible list (there were significant differences with the control list too). We will now use these data to calculate an **effect size** (*Cohen's d*) for the t-statistic that we observed in that test. 

2. Import the stroop data. We have reduced the data down to just the *compatible* and *incompatible* conditions. 

3. Run the `cohens_d()` code to calculate the effect size, which is reported as *effsize*. You can ignore any negative sign, taking note of the absolute value. 

4. We already know that this large effect size was significant with our large sample of participants. What might we have expected with a much smaller sample size? Use the `pwr.t.test()` function to add in the effect size that you calculated (Cohen's d) and set the *N* to 20. What **power** would we have achieved with this sample size, to detect this large effect? Discuss with your table, or staff, what this power means.

5. Let's say we wanted our next experiment to have an 80% chance of finding an effect at least as large as the one we found. Complete the `pwr.t.test()` function to work out the minimum sample size we would need to achieve power of .8, with this effect size.

6. Let's say we are looking to run a new experiment in which we give people a stressful task to complete simultaneously. We will ask them to put their hands in a bucket of ice cold water while doing the Stroop task (this is a real "stressor task" people use!). We are unsure of what consequence this will have for our effect size, but we want to estimate the effect size that could be detected in our experiment. We decide to run 40 participants, and want to achieve a power of .90 (90% chance to find an effect at least this large). What is the minimum effect size we could hope to detect under these conditions?











